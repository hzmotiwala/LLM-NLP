{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1366dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f62d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09629af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many people live in London?\"\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "#Load the model\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "#Encode query and documents\n",
    "query_emb = model.encode(query)\n",
    "doc_emb = model.encode(docs)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_score_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc_score_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1965861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe66cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "import tensorflow\n",
    "import keras\n",
    "import tensorflow.python.keras.engine\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d40db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9aabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"one day I will see the world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "premise = sequence\n",
    "hypothesis = f'This example is travel.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')\n",
    "logits = nli_model(x.to(cpu))[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "prob_label_is_true = probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b82344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"upstage/llama-30b-instruct-2048\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a49e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"upstage/llama-30b-instruct-2048\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"upstage/llama-30b-instruct-2048\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae5b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
