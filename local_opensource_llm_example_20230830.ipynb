{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47d10bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')\n",
    "\n",
    "# set pad_token_id to a specific value\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# create pipeline and set pad_token_id\n",
    "text_generator = pipeline('text-generation', model=model, tokenizer=tokenizer, pad_token_id=pad_token_id)\n",
    "\n",
    "# generate text\n",
    "generated_text = text_generator('Hello, how are you?', max_length=50)\n",
    "\n",
    "# print generated text\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1037ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc1f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "generated_text = text_generator('Hello, how are you?', max_length=500, do_sample=True, top_k=50, top_p=0.95)\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d425908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the risks associated to social media account ban and unban process?\n"
     ]
    }
   ],
   "source": [
    "generated_text = text_generator('what are the risks associated to social media account ban and unban process?', max_length=500, do_sample=True, top_k=50, top_p=0.95)\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ba14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81264cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92379f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d0084a8e724b3892dcf4790b4ac0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e351a65fb084217af3c149c3c89c6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23493a4d4efd4f8caddceb1ef958c48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89032cd80d224cb5a9676d499e053c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a141c5cca1e64f37941fe59e36fb332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? How are you?\"\n",
      "\n",
      "\"Well, if you come in one evening, there is nothing to be afraid of.\"\n",
      "\n",
      "\"Then, if you come in, I shall give you the order and stay for twenty\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load pre-trained model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# set prompt and generate output\n",
    "prompt = \"Hello, how are you?\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(input_ids=input_ids, max_length=50, do_sample=True, top_k=50, top_p=0.95)\n",
    "\n",
    "# decode generated output and print\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6483e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the risks associated to social media account ban and unban process?\n",
      "\n",
      "As we know, there are many different tools available at the moment, for the most part, for filtering, sharing, and banning. The general rules for blocking, sharing, and banning sites on your social media accounts vary depending on which tools are available. For example, users will most likely want to use a filter such as Facebook to see if certain topics are acceptable or unacceptable on Facebook. If so, then if you use the filter you will see certain categories such as \"offensive/horrible\" or \"sexist\".\n",
      "\n",
      "To see a list of what filtering tools are available, go to the Tools section of your account and click on your filter.\n",
      "\n",
      "As we know there are lots of different kinds of filters to choose from, and different filters can be tailored for different purposes, we will take the opportunity to provide you with some general guidelines for using these filters.\n",
      "\n",
      "All content has to be clearly marked, and as such, it will not be removed.\n",
      "\n",
      "All content must contain the following terms and conditions:\n",
      "\n",
      "Facebook uses personal information to identify users, such as their race, gender, religion, sexuality or disability.\n",
      "\n",
      "Social media accounts should not be shared or shared with anyone without the ability to identify and remove information from the account.\n",
      "\n",
      "Users should not use social media accounts without approval from a reputable online forum.\n",
      "\n",
      "Facebook uses data to protect personal information or users' identities, including those of their family or friends, that they choose to share with someone else.\n",
      "\n",
      "Your profile picture may be removed if it does not properly reflect what you have done and what others see or understand and can easily be re-used without a criminal prosecution.\n",
      "\n",
      "\n",
      "Social media accounts are only valid on a temporary basis, not for the full duration of the period set by your account. The terms of service of your account may change for the sake of the community and for other reasons. The purpose is to facilitate communication on social media, and is not to force you to give information on what people want or how much. Facebook may, in certain circumstances, refuse to allow you to post, share, or delete information, or you may be subject to any other circumstances which may affect your use of our platform.\n",
      "\n",
      "How do I keep track of my user information?\n",
      "\n",
      "As previously mentioned, Facebook does not store any personal information or data on you. You can\n"
     ]
    }
   ],
   "source": [
    "# set prompt and generate output\n",
    "prompt = \"what are the risks associated to social media account ban and unban process?\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(input_ids=input_ids, max_length=500, do_sample=True, top_k=50, top_p=0.95)\n",
    "\n",
    "# decode generated output and print\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0dac2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write a sql query to select employee name, email, location, leader_email, level from employee table for this employee.\n",
      "\n",
      "//\n",
      "\n",
      "# if DEBUG_PASSWORD // We want to use a password here\n",
      "\n",
      "# define DELETE_PASSWORD'0.0001'// use public key instead of private\n",
      "\n",
      "# else\n",
      "\n",
      "# define DELETE_PASSWORD'0.0001'// use private key instead of public key\n",
      "\n",
      "// <summary>\n",
      "\n",
      "# include < string.h >\n",
      "\n",
      "# include < string.h >\n",
      "\n",
      "# include < string.h >\n",
      "\n",
      "/*\n",
      "\n",
      "// <summary>\n",
      "\n",
      "//\n",
      "\n",
      "// The <sqlite3>\n",
      "\n",
      "// file allows you to provide an object to each field of a string.\n",
      "\n",
      "//\n",
      "\n",
      "// It's available with any value of 1 or 2 and can be overridden with\n",
      "\n",
      "// <string> or <string>=<parameter name> of the\n",
      "\n",
      "// <object> type.\n",
      "\n",
      "// If you wish to use <string> as a parameter to\n",
      "\n",
      "// <object> type, you can call this:\n",
      "\n",
      "// <string> = <parameter name>();\n",
      "\n",
      "//\n",
      "\n",
      "// <summary>\n",
      "\n",
      "//\n",
      "\n",
      "// The <sqlite3> file allows you to provide an object to each field of a\n",
      "\n",
      "// string.\n",
      "\n",
      "//\n",
      "\n",
      "// It's available with any value of 1 or 2 and can be overridden with\n",
      "\n",
      "// <string> or <string>=<parameter name> of the\n",
      "\n",
      "// <object> type. If you wish to use <string> as a parameter to\n",
      "\n",
      "// <object> type, you can call this:\n",
      "\n",
      "// <string> = <parameter name>();\n",
      "\n",
      "//\n",
      "\n",
      "// <summary>\n",
      "\n",
      "# include \" sqlite3.h \"\n",
      "\n",
      "# include \" sqlite3.h.h \"\n",
      "\n",
      "# include \" sqlite3.h.h.h_db \"\n",
      "\n",
      "//\n",
      "\n",
      "// The <sqlite3db> file allows you to provide an object to each field of a\n",
      "\n",
      "// database. You don't need an object of type <db> for data to be passed to other\n",
      "\n",
      "// functions.\n",
      "\n",
      "//\n",
      "\n",
      "// <summary>\n",
      "\n",
      "# include \" sqlite3\n"
     ]
    }
   ],
   "source": [
    "# set prompt and generate output\n",
    "prompt = \"write a sql query to select employee name, email, location, leader_email, level from employee table\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(input_ids=input_ids, max_length=500, do_sample=True, top_k=50, top_p=0.95)\n",
    "\n",
    "# decode generated output and print\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690ab24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d709b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "040f5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:write a sql query to select employee name, email, location, leader_email, level from employee d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: I'll try that, thanks!\n",
      ">> User:Can you actually provide the sql code?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: I'll try to find it, but I'm not sure if I can.\n",
      ">> User:what are the risks associated to social media account ban and unban process?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: I don't know, I don't use social media.\n",
      ">> User:what is a better schedule to work in office? Monday, Wednesday, Friday or Tuesday, Thursday, Friday?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: I'm not sure, I don't work in office.\n",
      ">> User:what data are you trained on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: I\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "# Let's chat for 5 lines\n",
    "for step in range(5):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "    # generated a response while limiting the total chat history to 1000 tokens,\n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3a0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ee473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a7cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b4f696d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1144497473.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    write a sql query to select employee name, email, location, leader_email, level from employee table\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "write a sql query to select employee name, email, location, leader_email, level from employee d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f7ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "what are the risks associated to social media account ban and unban process?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
